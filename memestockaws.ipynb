{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "memestockaws.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMhbuD6jdGgbCk6ZpwKn04i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gsalinas01/meme_stock_prices/blob/main/memestockaws.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-Ycxr0mTSJZ",
        "outputId": "168102aa-9389-473e-d803-d1889b5c32ba"
      },
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.3'\n",
        "spark_version = 'spark-3.0.3'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "import pyspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 3s (95.4 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bqfs3vhe2K0"
      },
      "source": [
        "### Postgres driver"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RugvxcsDTYne",
        "outputId": "9b9b4750-73e1-4ad9-922b-af15a506b8d2"
      },
      "source": [
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.16.jar"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-17 01:12:39--  https://jdbc.postgresql.org/download/postgresql-42.2.16.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1002883 (979K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.16.jar.2’\n",
            "\n",
            "postgresql-42.2.16. 100%[===================>] 979.38K  1.23MB/s    in 0.8s    \n",
            "\n",
            "2021-11-17 01:12:40 (1.23 MB/s) - ‘postgresql-42.2.16.jar.2’ saved [1002883/1002883]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dFEIgHATdjJ"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"memestockaws\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.16.jar\").getOrCreate()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASRRgJABuWUx"
      },
      "source": [
        "# RDS Database name: memestockdb\n",
        "# S3 Bucket name: memestockbucket\n",
        "# (RDS database has already been created)\n",
        "from pyspark import SparkFiles"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Icw7exgwelF0"
      },
      "source": [
        "## Loading data from S3 bucket into Spark DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjQAP5RBt1oc",
        "outputId": "9d99b8a4-9010-4334-c883-15e96a93d079"
      },
      "source": [
        "# Read in challenge data from S3 Buckets in AWS ________________________TSLA TWEETS 7 day - Hourly_______________________\n",
        "# TSLA tweets 7 day - Hourly\n",
        "\n",
        "url =\"https://memestockbucket.s3.amazonaws.com/TSLA_tweet_7days_prior_hist_2021_11_7_perhour.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "tweets_7day_hourly = spark.read.csv(SparkFiles.get(\"TSLA_tweet_7days_prior_hist_2021_11_7_perhour.csv\"), sep=\",\", header=True, inferSchema=True)\n",
        "tweets_7day_hourly.show(truncate=False)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+------------+-------------------+\n",
            "|_c0|Unnamed: 0|tweet_counts|date_UTC           |\n",
            "+---+----------+------------+-------------------+\n",
            "|0  |0         |22          |2021-10-31 18:00:00|\n",
            "|1  |1         |30          |2021-10-31 19:00:00|\n",
            "|2  |2         |16          |2021-10-31 20:00:00|\n",
            "|3  |3         |34          |2021-10-31 21:00:00|\n",
            "|4  |4         |93          |2021-10-31 22:00:00|\n",
            "|5  |5         |17          |2021-10-31 23:00:00|\n",
            "|6  |6         |18          |2021-10-31 00:00:00|\n",
            "|7  |7         |31          |2021-11-01 01:00:00|\n",
            "|8  |8         |49          |2021-11-01 02:00:00|\n",
            "|9  |9         |35          |2021-11-01 03:00:00|\n",
            "|10 |10        |46          |2021-11-01 04:00:00|\n",
            "|11 |11        |22          |2021-11-01 05:00:00|\n",
            "|12 |12        |9           |2021-11-01 06:00:00|\n",
            "|13 |13        |12          |2021-11-01 07:00:00|\n",
            "|14 |14        |27          |2021-11-01 08:00:00|\n",
            "|15 |15        |31          |2021-11-01 09:00:00|\n",
            "|16 |16        |52          |2021-11-01 10:00:00|\n",
            "|17 |17        |83          |2021-11-01 11:00:00|\n",
            "|18 |18        |92          |2021-11-01 12:00:00|\n",
            "|19 |19        |160         |2021-11-01 13:00:00|\n",
            "+---+----------+------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YestxKp90z-H",
        "outputId": "456f5285-8c78-4455-e3e2-a3bd36cbd3be"
      },
      "source": [
        "# Read in challenge data from S3 Buckets in AWS _____________________TSLA STOCK HISTORY 7 day - Hourly_______________________________\n",
        "# TSLA Stock History 7 day - Hourly\n",
        "url2 =\"https://memestockbucket.s3.amazonaws.com/TSLA_stock_hist_hourly_2021_11_7.csv\"\n",
        "spark.sparkContext.addFile(url2)\n",
        "tsla_stock_hourly = spark.read.csv(SparkFiles.get(\"TSLA_stock_hist_hourly_2021_11_7.csv\"), sep=\",\", header=True, inferSchema=True)\n",
        "tsla_stock_hourly.show(truncate=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------------+------------------+------------------+------------------+------------------+------------------+--------+---------------------+-------------------+\n",
            "|_c0|Unnamed: 0               |Open              |High              |Low               |Close             |Adj Close         |Volume  |Percent_Day_Change   |date_UTC           |\n",
            "+---+-------------------------+------------------+------------------+------------------+------------------+------------------+--------+---------------------+-------------------+\n",
            "|0  |2021-10-28 09:30:00-04:00|1068.3050537109377|1081.0            |1055.2099609375   |1060.3599853515623|1060.3599853515623|8788599 |-0.7437078324937674  |2021-10-28 14:00:00|\n",
            "|1  |2021-10-28 10:30:00-04:00|1060.1800537109377|1077.4649658203123|1058.8900146484377|1070.250732421875 |1070.250732421875 |4857422 |0.9499026769733244   |2021-10-28 15:00:00|\n",
            "|2  |2021-10-28 11:30:00-04:00|1070.83984375     |1079.68994140625  |1064.3499755859377|1076.3800048828123|1076.3800048828123|3591916 |0.5173659875608694   |2021-10-28 16:00:00|\n",
            "|3  |2021-10-28 12:30:00-04:00|1076.949951171875 |1079.64990234375  |1066.0            |1073.175048828125 |1073.175048828125 |3328912 |-0.35051789915050424 |2021-10-28 17:00:00|\n",
            "|4  |2021-10-28 13:30:00-04:00|1073.25           |1074.030029296875 |1067.5899658203123|1072.9100341796877|1072.9100341796877|1543551 |-0.031676293530169534|2021-10-28 18:00:00|\n",
            "|5  |2021-10-28 14:30:00-04:00|1072.7701416015623|1073.2498779296877|1066.1099853515623|1069.93505859375  |1069.93505859375  |1703906 |-0.26427683786760525 |2021-10-28 19:00:00|\n",
            "|6  |2021-10-28 15:30:00-04:00|1069.753173828125 |1077.760009765625 |1067.5            |1077.0899658203123|1077.0899658203123|1714894 |0.6858397031842989   |2021-10-28 20:00:00|\n",
            "|7  |2021-10-29 09:30:00-04:00|1080.0            |1100.0            |1073.2049560546877|1088.39013671875  |1088.39013671875  |9855755 |0.7768645109953676   |2021-10-29 14:00:00|\n",
            "|8  |2021-10-29 10:30:00-04:00|1088.75           |1094.8800048828123|1086.5999755859377|1091.3800048828123|1091.3800048828123|3616633 |0.24156187212973634  |2021-10-29 15:00:00|\n",
            "|9  |2021-10-29 11:30:00-04:00|1091.3599853515623|1098.0            |1088.5999755859377|1092.3599853515623|1092.3599853515623|2628858 |0.0916287946619132   |2021-10-29 16:00:00|\n",
            "|10 |2021-10-29 12:30:00-04:00|1092.2601318359377|1105.8599853515623|1090.97998046875  |1101.8199462890623|1101.8199462890623|3122589 |0.8752323896557668   |2021-10-29 17:00:00|\n",
            "|11 |2021-10-29 13:30:00-04:00|1101.9512939453123|1103.0            |1094.780029296875 |1096.7781982421877|1096.7781982421877|2491949 |-0.469448670875805   |2021-10-29 18:00:00|\n",
            "|12 |2021-10-29 14:30:00-04:00|1096.685302734375 |1102.0            |1093.0            |1100.5699462890623|1100.5699462890623|2452751 |0.3542167971980481   |2021-10-29 19:00:00|\n",
            "|13 |2021-10-29 15:30:00-04:00|1100.530029296875 |1115.2099609375   |1100.1199951171877|1114.1800537109377|1114.1800537109377|3788587 |1.2403136716572227   |2021-10-29 20:00:00|\n",
            "|14 |2021-11-01 09:30:00-04:00|1145.0            |1150.0            |1118.6600341796877|1135.364990234375 |1135.364990234375 |14824885|-0.8414855690502154  |2021-11-01 14:00:00|\n",
            "|15 |2021-11-01 10:30:00-04:00|1135.300048828125 |1162.36474609375  |1132.56005859375  |1161.3751220703125|1161.3751220703125|7175951 |2.2967561103430345   |2021-11-01 15:00:00|\n",
            "|16 |2021-11-01 11:30:00-04:00|1161.219970703125 |1175.75           |1154.240234375    |1170.02001953125  |1170.02001953125  |6567429 |0.7578278922292903   |2021-11-01 16:00:00|\n",
            "|17 |2021-11-01 12:30:00-04:00|1170.1690673828125|1193.489990234375 |1167.050048828125 |1172.4000244140625|1172.4000244140625|7126538 |0.19065253846093366  |2021-11-01 17:00:00|\n",
            "|18 |2021-11-01 13:30:00-04:00|1172.4000244140625|1178.97998046875  |1162.2099609375   |1167.06005859375  |1167.06005859375  |5269389 |-0.4554730219304859  |2021-11-01 18:00:00|\n",
            "|19 |2021-11-01 14:30:00-04:00|1166.969970703125 |1191.0            |1166.02001953125  |1191.0            |1191.0            |5371085 |2.0591814614043797   |2021-11-01 19:00:00|\n",
            "+---+-------------------------+------------------+------------------+------------------+------------------+------------------+--------+---------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UgvkqvBc59z",
        "outputId": "b188e9a7-44fa-4b59-97ae-c54f39caaf78"
      },
      "source": [
        "# Read in challenge data from S3 Buckets in AWS _____________________SPY History 7 day - Hourly_______________________________\n",
        "# SPY History 7 day - Hourly\n",
        "url34 =\"https://memestockbucket.s3.amazonaws.com/SPY_stock_hist_hourly_2021_11_7.csv\"\n",
        "spark.sparkContext.addFile(url34)\n",
        "SPY_7_day_hourly = spark.read.csv(SparkFiles.get(\"SPY_stock_hist_hourly_2021_11_7.csv\"), sep=\",\", header=True, inferSchema=True)\n",
        "SPY_7_day_hourly.show(truncate=False)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------------+------------------+------------------+------------------+------------------+------------------+--------+---------------------+-------------------+\n",
            "|_c0|Unnamed: 0               |Open              |High              |Low               |Close             |Adj Close         |Volume  |Percent_Day_Change   |date_UTC           |\n",
            "+---+-------------------------+------------------+------------------+------------------+------------------+------------------+--------+---------------------+-------------------+\n",
            "|0  |2021-10-28 09:30:00-04:00|455.8999938964844 |457.125           |455.68011474609375|457.05999755859375|457.05999755859375|9880982 |0.2544425702213804   |2021-10-28 14:00:00|\n",
            "|1  |2021-10-28 10:30:00-04:00|457.0700073242188 |457.97601318359375|457.0             |457.5199890136719 |457.5199890136719 |5874814 |0.09844918332913012  |2021-10-28 15:00:00|\n",
            "|2  |2021-10-28 11:30:00-04:00|457.5299987792969 |457.95001220703125|456.8599853515625 |457.2999877929688 |457.2999877929688 |4100046 |-0.05027232901488876 |2021-10-28 16:00:00|\n",
            "|3  |2021-10-28 12:30:00-04:00|457.30499267578125|457.42999267578125|456.5             |457.0499877929688 |457.0499877929688 |3684041 |-0.055762540732484656|2021-10-28 17:00:00|\n",
            "|4  |2021-10-28 13:30:00-04:00|457.05999755859375|457.8699951171875 |457.052490234375  |457.7799987792969 |457.7799987792969 |7065893 |0.15752881996873302  |2021-10-28 18:00:00|\n",
            "|5  |2021-10-28 14:30:00-04:00|457.7799987792969 |457.9100036621094 |457.0928955078125 |457.239990234375  |457.239990234375  |4430106 |-0.11796245933894944 |2021-10-28 19:00:00|\n",
            "|6  |2021-10-28 15:30:00-04:00|457.2300109863281 |458.3999938964844 |457.1000061035156 |458.260009765625  |458.260009765625  |9957417 |0.2252692855998273   |2021-10-28 20:00:00|\n",
            "|7  |2021-10-29 09:30:00-04:00|455.8699951171875 |457.6400146484375 |455.55999755859375|456.739990234375  |456.739990234375  |12038991|0.19084281187751184  |2021-10-29 14:00:00|\n",
            "|8  |2021-10-29 10:30:00-04:00|456.7699890136719 |458.2099914550781 |456.4800109863281 |458.05999755859375|458.05999755859375|7632336 |0.2824197245767879   |2021-10-29 15:00:00|\n",
            "|9  |2021-10-29 11:30:00-04:00|458.0499877929688 |459.1650085449219 |457.7900085449219 |459.1400146484375 |459.1400146484375 |7816773 |0.237971156973682    |2021-10-29 16:00:00|\n",
            "|10 |2021-10-29 12:30:00-04:00|459.1400146484375 |459.1499938964844 |458.6499938964844 |458.8500061035156 |458.8500061035156 |4431218 |-0.06316342197791869 |2021-10-29 17:00:00|\n",
            "|11 |2021-10-29 13:30:00-04:00|458.8599853515625 |458.8900146484375 |457.8200073242188 |457.8299865722656 |457.8299865722656 |4966186 |-0.22446907818900466 |2021-10-29 18:00:00|\n",
            "|12 |2021-10-29 14:30:00-04:00|457.8299865722656 |458.3599853515625 |457.5799865722656 |457.9049987792969 |457.9049987792969 |8509170 |0.016384293128735017 |2021-10-29 19:00:00|\n",
            "|13 |2021-10-29 15:30:00-04:00|457.8999938964844 |459.55999755859375|457.7900085449219 |459.2200012207031 |459.2200012207031 |15568733|0.2882741519575571   |2021-10-29 20:00:00|\n",
            "|14 |2021-11-01 09:30:00-04:00|460.17999267578125|460.70208740234375|458.2099914550781 |459.0400085449219 |459.0400085449219 |13992445|-0.24772570494226984 |2021-11-01 14:00:00|\n",
            "|15 |2021-11-01 10:30:00-04:00|459.0299987792969 |459.4400024414063 |458.260009765625  |459.2300109863281 |459.2300109863281 |5841979 |0.043572796454083296 |2021-11-01 15:00:00|\n",
            "|16 |2021-11-01 11:30:00-04:00|459.2300109863281 |459.7300109863281 |459.010009765625  |459.6749877929688 |459.6749877929688 |3451053 |0.09689628203628507  |2021-11-01 16:00:00|\n",
            "|17 |2021-11-01 12:30:00-04:00|459.67999267578125|460.0199890136719 |459.1000061035156 |459.25            |459.25            |3957074 |-0.09354174265411297 |2021-11-01 17:00:00|\n",
            "|18 |2021-11-01 13:30:00-04:00|459.260009765625  |459.3900146484375 |458.2200012207031 |458.6300048828125 |458.6300048828125 |3724726 |-0.13717825837569195 |2021-11-01 18:00:00|\n",
            "|19 |2021-11-01 14:30:00-04:00|458.6099853515625 |459.5400085449219 |458.6099853515625 |459.3900146484375 |459.3900146484375 |3669787 |0.1700855458428352   |2021-11-01 19:00:00|\n",
            "+---+-------------------------+------------------+------------------+------------------+------------------+------------------+--------+---------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbQAqIfKmXdG",
        "outputId": "9d7bd0dc-2bb0-4989-d2b5-b559d0048d56"
      },
      "source": [
        "# DROP NAs\n",
        "tweets_7day_hourly.dropna()\n",
        "tsla_stock_hourly.dropna()\n",
        "SPY_7_day_hourly.dropna()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[_c0: int, Unnamed: 0: string, Open: double, High: double, Low: double, Close: double, Adj Close: double, Volume: int, Percent_Day_Change: double, date_UTC: string]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdlYV2UanyqR"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXSRq8LynzH3"
      },
      "source": [
        "CLEAN UP DATA into DFs for tables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7a--ZpZnKz1",
        "outputId": "56a00d21-ecf5-4d02-a6e1-b536992fde6a"
      },
      "source": [
        "clean_tweets_hourly = tweets_7day_hourly[\"tweet_counts\",\"date_UTC\"]\n",
        "clean_tweets_hourly.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------------------+\n",
            "|tweet_counts|           date_UTC|\n",
            "+------------+-------------------+\n",
            "|          22|2021-10-31 18:00:00|\n",
            "|          30|2021-10-31 19:00:00|\n",
            "|          16|2021-10-31 20:00:00|\n",
            "|          34|2021-10-31 21:00:00|\n",
            "|          93|2021-10-31 22:00:00|\n",
            "|          17|2021-10-31 23:00:00|\n",
            "|          18|2021-10-31 00:00:00|\n",
            "|          31|2021-11-01 01:00:00|\n",
            "|          49|2021-11-01 02:00:00|\n",
            "|          35|2021-11-01 03:00:00|\n",
            "|          46|2021-11-01 04:00:00|\n",
            "|          22|2021-11-01 05:00:00|\n",
            "|           9|2021-11-01 06:00:00|\n",
            "|          12|2021-11-01 07:00:00|\n",
            "|          27|2021-11-01 08:00:00|\n",
            "|          31|2021-11-01 09:00:00|\n",
            "|          52|2021-11-01 10:00:00|\n",
            "|          83|2021-11-01 11:00:00|\n",
            "|          92|2021-11-01 12:00:00|\n",
            "|         160|2021-11-01 13:00:00|\n",
            "+------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESzNaDWon_Jz",
        "outputId": "b761b46c-5942-44b4-9e12-b11a4381486c"
      },
      "source": [
        "clean_tsla_stock_hourly = tsla_stock_hourly[\"Percent_Day_Change\",\"date_UTC\"]\n",
        "clean_tsla_stock_hourly.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------------+\n",
            "|  Percent_Day_Change|           date_UTC|\n",
            "+--------------------+-------------------+\n",
            "| -0.7437078324937674|2021-10-28 14:00:00|\n",
            "|  0.9499026769733244|2021-10-28 15:00:00|\n",
            "|  0.5173659875608694|2021-10-28 16:00:00|\n",
            "|-0.35051789915050424|2021-10-28 17:00:00|\n",
            "|-0.03167629353016...|2021-10-28 18:00:00|\n",
            "|-0.26427683786760525|2021-10-28 19:00:00|\n",
            "|  0.6858397031842989|2021-10-28 20:00:00|\n",
            "|  0.7768645109953676|2021-10-29 14:00:00|\n",
            "| 0.24156187212973634|2021-10-29 15:00:00|\n",
            "|  0.0916287946619132|2021-10-29 16:00:00|\n",
            "|  0.8752323896557668|2021-10-29 17:00:00|\n",
            "|  -0.469448670875805|2021-10-29 18:00:00|\n",
            "|  0.3542167971980481|2021-10-29 19:00:00|\n",
            "|  1.2403136716572227|2021-10-29 20:00:00|\n",
            "| -0.8414855690502154|2021-11-01 14:00:00|\n",
            "|  2.2967561103430345|2021-11-01 15:00:00|\n",
            "|  0.7578278922292903|2021-11-01 16:00:00|\n",
            "| 0.19065253846093366|2021-11-01 17:00:00|\n",
            "| -0.4554730219304859|2021-11-01 18:00:00|\n",
            "|  2.0591814614043797|2021-11-01 19:00:00|\n",
            "+--------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB0c0NIeoctf",
        "outputId": "0189bd33-ce09-4d4c-ed1e-83fce0caa0b9"
      },
      "source": [
        "clean_SPY_hourly = SPY_7_day_hourly[\"Percent_Day_Change\",\"date_UTC\"]\n",
        "clean_SPY_hourly.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------------+\n",
            "|  Percent_Day_Change|           date_UTC|\n",
            "+--------------------+-------------------+\n",
            "|  0.2544425702213804|2021-10-28 14:00:00|\n",
            "| 0.09844918332913012|2021-10-28 15:00:00|\n",
            "|-0.05027232901488876|2021-10-28 16:00:00|\n",
            "|-0.05576254073248...|2021-10-28 17:00:00|\n",
            "| 0.15752881996873302|2021-10-28 18:00:00|\n",
            "|-0.11796245933894944|2021-10-28 19:00:00|\n",
            "|  0.2252692855998273|2021-10-28 20:00:00|\n",
            "| 0.19084281187751184|2021-10-29 14:00:00|\n",
            "|  0.2824197245767879|2021-10-29 15:00:00|\n",
            "|   0.237971156973682|2021-10-29 16:00:00|\n",
            "|-0.06316342197791869|2021-10-29 17:00:00|\n",
            "|-0.22446907818900466|2021-10-29 18:00:00|\n",
            "|0.016384293128735017|2021-10-29 19:00:00|\n",
            "|  0.2882741519575571|2021-10-29 20:00:00|\n",
            "|-0.24772570494226984|2021-11-01 14:00:00|\n",
            "|0.043572796454083296|2021-11-01 15:00:00|\n",
            "| 0.09689628203628507|2021-11-01 16:00:00|\n",
            "|-0.09354174265411297|2021-11-01 17:00:00|\n",
            "|-0.13717825837569195|2021-11-01 18:00:00|\n",
            "|  0.1700855458428352|2021-11-01 19:00:00|\n",
            "+--------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWivE8bEVaUz"
      },
      "source": [
        "# LOAD PHASE (to Postgres) ______________________LOAD PHASE ______________________LOAD PHASE ______________________LOAD PHASE ______________________"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SfffyscVe0w"
      },
      "source": [
        "# configure settings for RDS\n",
        "mode = \"overwrite\"\n",
        "jdbc_url=\"jdbc:postgresql://memestockdb.cfgrdqp4dywh.us-east-1.rds.amazonaws.com:5432/memestockdb\"\n",
        "config = {\"user\":\"postgres\",\n",
        "          \"password\":\"MemeStock123!\",\n",
        "          \"driver\":\"org.postresql.Driver\"}"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q9lo13kya2gJ",
        "outputId": "2728dad1-0f98-412c-ead3-07ca59fc8f16"
      },
      "source": [
        "# write df table in RDS\n",
        "clean_tweets_hourly.write.jdbc(url=jdbc_url, table='clean_tweets_hourly', mode=mode, properties=config)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-7b37b531ec50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# write df table in RDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclean_tweets_hourly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjdbc_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'clean_tweets_hourly'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mjdbc\u001b[0;34m(self, url, table, mode, properties)\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0mjprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetProperty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o115.jdbc.\n: java.lang.ClassNotFoundException: org.postresql.Driver\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:471)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:589)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)\n\tat org.apache.spark.sql.execution.datasources.jdbc.DriverRegistry$.register(DriverRegistry.scala:45)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1(JDBCOptions.scala:99)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1$adapted(JDBCOptions.scala:99)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:99)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:194)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:198)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:45)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:46)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:90)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:127)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:126)\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:962)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:767)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:962)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:414)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:398)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:790)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
          ]
        }
      ]
    }
  ]
}